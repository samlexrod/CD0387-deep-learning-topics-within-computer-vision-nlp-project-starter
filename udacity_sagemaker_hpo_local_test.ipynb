{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "740fe431-f01d-44ae-9ea6-add181724216",
   "metadata": {},
   "source": [
    "# Save sample data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eea1e1d-c037-42d3-b6f3-0805f259f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:07<00:00, 10.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# List all objects helper internal function\n",
    "def list_all_objects(bucket, prefix):\n",
    "    # Create a paginator for list_objects_v2\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "\n",
    "    # Use the paginator to iterate through all pages\n",
    "    all_objects = []\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        if 'Contents' in page:\n",
    "            all_objects.extend(page['Contents'])\n",
    "\n",
    "    return all_objects\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "prefix = 'data'\n",
    "sample_prefix = 'sample'\n",
    "\n",
    "all_files = list_all_objects(bucket, prefix)\n",
    "\n",
    "sample_files = [file_meta for file_meta in all_files if '001.Affenpinscher' in file_meta.get(\"Key\")]\n",
    "\n",
    "for file_meta in tqdm(sample_files):\n",
    "    key = file_meta.get(\"Key\")\n",
    "    \n",
    "    # Move the data from s3 to a different prefix\n",
    "    dirname = os.path.dirname(key)\n",
    "    if dirname:\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "    s3.download_file(bucket, key, key)\n",
    "    # s3.copy_object(\n",
    "    #     Bucket=bucket,\n",
    "    #     CopySource=f\"{bucket}/{key}\",\n",
    "    #     Key=f\"{sample_prefix}/{key}\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201b549-bd17-499a-8a6f-05752ef5cb08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Estimator Locally Prior to Deployment to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87553aa0-2f98-4f0a-b3fb-e2dd11ec3053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:de7a6ff5d9bb2950d37a327228b33e8e1ee45339b81518da342c9f32c44424e9\n",
      "REPOSITORY              TAG       IMAGE ID       CREATED                  SIZE\n",
      "udacity-sagemaker-hpo   latest    de7a6ff5d9bb   Less than a second ago   3.92GB\n",
      "<none>                  <none>    4a21c8e53d63   4 minutes ago            3.92GB\n",
      "<none>                  <none>    0814594320ea   8 minutes ago            3.92GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: udacity-sagemaker-hpo-2024-11-26-13-16-44-757\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-b9y75:\n",
      "    command: train\n",
      "    container_name: t4grlud1y8-algo-1-b9y75\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: udacity-sagemaker-hpo\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-b9y75\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpe6gw00li/algo-1-b9y75/output:/opt/ml/output\n",
      "    - /tmp/tmpe6gw00li/algo-1-b9y75/input:/opt/ml/input\n",
      "    - /tmp/tmpe6gw00li/algo-1-b9y75/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpe6gw00li/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter/data/test:/opt/ml/input/data/train\n",
      "    - /home/ec2-user/SageMaker/CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter/data/valid:/opt/ml/input/data/test\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpe6gw00li/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Container t4grlud1y8-algo-1-b9y75  Creating\n",
      " Container t4grlud1y8-algo-1-b9y75  Created\n",
      "Attaching to t4grlud1y8-algo-1-b9y75\n",
      "t4grlud1y8-algo-1-b9y75  | sed: can't read changehostname.c: No such file or directory\n",
      "t4grlud1y8-algo-1-b9y75  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kchangehostname.c: No such file or directory\n",
      "t4grlud1y8-algo-1-b9y75  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
      "t4grlud1y8-algo-1-b9y75  | compilation terminated.\n",
      "t4grlud1y8-algo-1-b9y75  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kchangehostname.o: No such file or directory\n",
      "t4grlud1y8-algo-1-b9y75  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,821 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,824 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,825 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\n",
      "t4grlud1y8-algo-1-b9y75  | Returning the value itself\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,837 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,844 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,848 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,848 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\n",
      "t4grlud1y8-algo-1-b9y75  | Returning the value itself\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,863 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,864 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\n",
      "t4grlud1y8-algo-1-b9y75  | Returning the value itself\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,879 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,880 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\n",
      "t4grlud1y8-algo-1-b9y75  | Returning the value itself\n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:16:45,892 sagemaker-training-toolkit INFO     Invoking user script\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Training Env:\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | {\n",
      "t4grlud1y8-algo-1-b9y75  |     \"additional_framework_parameters\": {},\n",
      "t4grlud1y8-algo-1-b9y75  |     \"channel_input_dirs\": {\n",
      "t4grlud1y8-algo-1-b9y75  |         \"train\": \"/opt/ml/input/data/train\",\n",
      "t4grlud1y8-algo-1-b9y75  |         \"test\": \"/opt/ml/input/data/test\"\n",
      "t4grlud1y8-algo-1-b9y75  |     },\n",
      "t4grlud1y8-algo-1-b9y75  |     \"current_host\": \"algo-1-b9y75\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"hosts\": [\n",
      "t4grlud1y8-algo-1-b9y75  |         \"algo-1-b9y75\"\n",
      "t4grlud1y8-algo-1-b9y75  |     ],\n",
      "t4grlud1y8-algo-1-b9y75  |     \"hyperparameters\": {\n",
      "t4grlud1y8-algo-1-b9y75  |         \"model-type\": \"vgg16\",\n",
      "t4grlud1y8-algo-1-b9y75  |         \"num-classes\": 133,\n",
      "t4grlud1y8-algo-1-b9y75  |         \"batch-size\": 32,\n",
      "t4grlud1y8-algo-1-b9y75  |         \"lr\": 0.005070970373087015\n",
      "t4grlud1y8-algo-1-b9y75  |     },\n",
      "t4grlud1y8-algo-1-b9y75  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"input_data_config\": {\n",
      "t4grlud1y8-algo-1-b9y75  |         \"train\": {\n",
      "t4grlud1y8-algo-1-b9y75  |             \"TrainingInputMode\": \"File\"\n",
      "t4grlud1y8-algo-1-b9y75  |         },\n",
      "t4grlud1y8-algo-1-b9y75  |         \"test\": {\n",
      "t4grlud1y8-algo-1-b9y75  |             \"TrainingInputMode\": \"File\"\n",
      "t4grlud1y8-algo-1-b9y75  |         }\n",
      "t4grlud1y8-algo-1-b9y75  |     },\n",
      "t4grlud1y8-algo-1-b9y75  |     \"input_dir\": \"/opt/ml/input\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"is_master\": true,\n",
      "t4grlud1y8-algo-1-b9y75  |     \"job_name\": \"udacity-sagemaker-hpo-2024-11-26-13-16-44-757\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"log_level\": 20,\n",
      "t4grlud1y8-algo-1-b9y75  |     \"master_hostname\": \"algo-1-b9y75\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"model_dir\": \"/opt/ml/model\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"module_dir\": \"/opt/ml/code\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"module_name\": \"hpo\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"network_interface_name\": \"eth0\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"num_cpus\": 2,\n",
      "t4grlud1y8-algo-1-b9y75  |     \"num_gpus\": 0,\n",
      "t4grlud1y8-algo-1-b9y75  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"output_dir\": \"/opt/ml/output\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "t4grlud1y8-algo-1-b9y75  |     \"resource_config\": {\n",
      "t4grlud1y8-algo-1-b9y75  |         \"current_host\": \"algo-1-b9y75\",\n",
      "t4grlud1y8-algo-1-b9y75  |         \"hosts\": [\n",
      "t4grlud1y8-algo-1-b9y75  |             \"algo-1-b9y75\"\n",
      "t4grlud1y8-algo-1-b9y75  |         ]\n",
      "t4grlud1y8-algo-1-b9y75  |     },\n",
      "t4grlud1y8-algo-1-b9y75  |     \"user_entry_point\": \"hpo.py\"\n",
      "t4grlud1y8-algo-1-b9y75  | }\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Environment variables:\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | SM_HOSTS=[\"algo-1-b9y75\"]\n",
      "t4grlud1y8-algo-1-b9y75  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "t4grlud1y8-algo-1-b9y75  | SM_HPS={\"batch-size\":32,\"lr\":0.005070970373087015,\"model-type\":\"vgg16\",\"num-classes\":133}\n",
      "t4grlud1y8-algo-1-b9y75  | SM_USER_ENTRY_POINT=hpo.py\n",
      "t4grlud1y8-algo-1-b9y75  | SM_FRAMEWORK_PARAMS={}\n",
      "t4grlud1y8-algo-1-b9y75  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-b9y75\",\"hosts\":[\"algo-1-b9y75\"]}\n",
      "t4grlud1y8-algo-1-b9y75  | SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "t4grlud1y8-algo-1-b9y75  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "t4grlud1y8-algo-1-b9y75  | SM_CHANNELS=[\"test\",\"train\"]\n",
      "t4grlud1y8-algo-1-b9y75  | SM_CURRENT_HOST=algo-1-b9y75\n",
      "t4grlud1y8-algo-1-b9y75  | SM_MODULE_NAME=hpo\n",
      "t4grlud1y8-algo-1-b9y75  | SM_LOG_LEVEL=20\n",
      "t4grlud1y8-algo-1-b9y75  | SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "t4grlud1y8-algo-1-b9y75  | SM_INPUT_DIR=/opt/ml/input\n",
      "t4grlud1y8-algo-1-b9y75  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "t4grlud1y8-algo-1-b9y75  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "t4grlud1y8-algo-1-b9y75  | SM_NUM_CPUS=2\n",
      "t4grlud1y8-algo-1-b9y75  | SM_NUM_GPUS=0\n",
      "t4grlud1y8-algo-1-b9y75  | SM_MODEL_DIR=/opt/ml/model\n",
      "t4grlud1y8-algo-1-b9y75  | SM_MODULE_DIR=/opt/ml/code\n",
      "t4grlud1y8-algo-1-b9y75  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-b9y75\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-b9y75\"],\"hyperparameters\":{\"batch-size\":32,\"lr\":0.005070970373087015,\"model-type\":\"vgg16\",\"num-classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"udacity-sagemaker-hpo-2024-11-26-13-16-44-757\",\"log_level\":20,\"master_hostname\":\"algo-1-b9y75\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"hpo\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-b9y75\",\"hosts\":[\"algo-1-b9y75\"]},\"user_entry_point\":\"hpo.py\"}\n",
      "t4grlud1y8-algo-1-b9y75  | SM_USER_ARGS=[\"--batch-size\",\"32\",\"--lr\",\"0.005070970373087015\",\"--model-type\",\"vgg16\",\"--num-classes\",\"133\"]\n",
      "t4grlud1y8-algo-1-b9y75  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "t4grlud1y8-algo-1-b9y75  | SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "t4grlud1y8-algo-1-b9y75  | SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "t4grlud1y8-algo-1-b9y75  | SM_HP_MODEL-TYPE=vgg16\n",
      "t4grlud1y8-algo-1-b9y75  | SM_HP_NUM-CLASSES=133\n",
      "t4grlud1y8-algo-1-b9y75  | SM_HP_BATCH-SIZE=32\n",
      "t4grlud1y8-algo-1-b9y75  | SM_HP_LR=0.005070970373087015\n",
      "t4grlud1y8-algo-1-b9y75  | PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Invoking script with the following command:\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | /opt/conda/bin/python3.6 hpo.py --batch-size 32 --lr 0.005070970373087015 --model-type vgg16 --num-classes 133\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | -> Selected model type: vgg16\n",
      "t4grlud1y8-algo-1-b9y75  | -> Loading pretrained model...\n",
      "t4grlud1y8-algo-1-b9y75  | -> Freezing pre-trained model layers...\n",
      "t4grlud1y8-algo-1-b9y75  | -> Replacing pre-trained model classifier with 133 classes...\n",
      "t4grlud1y8-algo-1-b9y75  | ************************************************************\n",
      "t4grlud1y8-algo-1-b9y75  | -> USING LOCAL RUN...\n",
      "t4grlud1y8-algo-1-b9y75  | -> Using cross_entropy loss criterion...\n",
      "t4grlud1y8-algo-1-b9y75  | -> Using Adadelta optimizer...\n",
      "t4grlud1y8-algo-1-b9y75  | -> Creating custom data loaders...\n",
      "t4grlud1y8-algo-1-b9y75  | ************************************************************\n",
      "t4grlud1y8-algo-1-b9y75  | -> Starting model training...\n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 1 [0/8 (0%)]\tLoss: 5.195677\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5645, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 2 [0/8 (0%)]\tLoss: 4.834945\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5620, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 3 [0/8 (0%)]\tLoss: 5.002045\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5594, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 4 [0/8 (0%)]\tLoss: 4.870584\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5568, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 5 [0/8 (0%)]\tLoss: 4.807518\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5542, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 6 [0/8 (0%)]\tLoss: 4.899691\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5517, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 7 [0/8 (0%)]\tLoss: 4.777834\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5491, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 8 [0/8 (0%)]\tLoss: 4.748045\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5466, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 9 [0/8 (0%)]\tLoss: 4.819732\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5440, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Train Epoch: 10 [0/8 (0%)]\tLoss: 4.810478\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | Test set: Average loss: 0.5416, Accuracy: 0/8 (0%)\n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | -> TorchScript model saved to /opt/ml/model/model.pth\n",
      "t4grlud1y8-algo-1-b9y75  | -> TorchScript model loaded successfully for verification.\n",
      "t4grlud1y8-algo-1-b9y75  | -> TorchScript model verification successful: Forward pass completed.\n",
      "t4grlud1y8-algo-1-b9y75  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "t4grlud1y8-algo-1-b9y75  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "t4grlud1y8-algo-1-b9y75  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "t4grlud1y8-algo-1-b9y75  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "t4grlud1y8-algo-1-b9y75  | Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:04<00:00, 124MB/s] \n",
      "1it [00:03,  3.02s/it]5  | \n",
      "1it [00:02,  2.98s/it]5  | \n",
      "1it [00:02,  2.84s/it]5  | \n",
      "1it [00:02,  2.97s/it]5  | \n",
      "1it [00:02,  2.95s/it]5  | \n",
      "1it [00:02,  2.96s/it]5  | \n",
      "1it [00:02,  2.91s/it]5  | \n",
      "1it [00:02,  2.98s/it]5  | \n",
      "1it [00:03,  3.11s/it]5  | \n",
      "1it [00:03,  3.61s/it]5  | \n",
      "t4grlud1y8-algo-1-b9y75  | \n",
      "t4grlud1y8-algo-1-b9y75  | 2024-11-26 13:18:05,476 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "t4grlud1y8-algo-1-b9y75 exited with code 0\n",
      "Aborting on container exit...\n",
      " Container t4grlud1y8-algo-1-b9y75  Stopping\n",
      " Container t4grlud1y8-algo-1-b9y75  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmpe6gw00li/algo-1-b9y75 Please remove it manually.\n",
      "INFO:sagemaker.local.image:===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(['sh', 'docker-build.sh'])\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "sample_prefix = 'sample'\n",
    "\n",
    "hyperparameters = {\n",
    "    'model-type': 'vgg16',\n",
    "    'num-classes': 133,\n",
    "    'batch-size': 32,\n",
    "    'lr': 0.005070970373087015\n",
    "}\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "s3_output_location = f\"s3://{bucket}/outputs\"\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='udacity-sagemaker-hpo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "model_inputs = {\n",
    "    \"train\": \"file://./data/test\",\n",
    "    \"test\": \"file://./data/valid\"\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=model_inputs, logs=True ,wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d3514-bc1c-40d5-a000-97292ccb17c8",
   "metadata": {},
   "source": [
    "## Testing Deployed Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f43502-7b17-4fa6-bddd-90a3271bb641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push-container.sh: line 1: fg: no job control\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (1/1) FINISHED                                 docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2B                                         0.0s\n",
      "\u001b[0m\u001b[?25hERROR: failed to solve: failed to read dockerfile: open Dockerfile: no such file or directory\n",
      "The push refers to repository [598308907998.dkr.ecr.us-east-1.amazonaws.com/udacity-sagemaker-hpo]\n",
      "\n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B77796a3a: Preparing \n",
      "\u001b[1Bb282a0ff: Preparing \n",
      "\u001b[1B95045e04: Preparing \n",
      "\u001b[1Be9708ca1: Preparing \n",
      "\u001b[1B8f6060c6: Preparing \n",
      "\u001b[1Ba3c12226: Preparing \n",
      "\u001b[1B62daa95e: Preparing \n",
      "\u001b[1B8fe1cb59: Preparing \n",
      "\u001b[1B061a5b0d: Preparing \n",
      "\u001b[1B3ff1bf08: Preparing \n",
      "\u001b[1Bfc0e8a35: Preparing \n",
      "\u001b[1B6a8aee3d: Preparing \n",
      "\u001b[1Be27443e4: Preparing \n",
      "\u001b[1Bd2b930fc: Preparing \n",
      "\u001b[1Bec0db89a: Preparing \n",
      "\u001b[1B49baa658: Preparing \n",
      "\u001b[1B56d8b3f9: Layer already exists \u001b[12A\u001b[2K\u001b[10A\u001b[2K\u001b[8A\u001b[2K\u001b[5A\u001b[2Klatest: digest: sha256:ce007e93b462c2311a7d8fd3c6453984d5b0a83c2360f6bc7959cff43738477d size: 4080\n"
     ]
    }
   ],
   "source": [
    "!sh push-container.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "070d573d-0e9e-4862-a5c6-384483849ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_inputs = {\n",
    "    \"train\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/{sample_prefix}/data/train/\",\n",
    "        content_type=\"application/x-image\"\n",
    "    ),\n",
    "    \"test\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/{sample_prefix}/data/valid/\",\n",
    "        content_type=\"application/x-image\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db355544-0e4d-424b-b8e7-246a93e08c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'model-type': 'vgg16',\n",
    "    'num-classes': 133,\n",
    "    'batch-size': 32,\n",
    "    'lr': 0.005070970373087015\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ace2c8-ca83-4f3f-93a2-16d0126e1cdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: udacity-sagemaker-hpo-2024-11-26-13-19-14-190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-26 13:19:16 Starting - Starting the training job...\n",
      "2024-11-26 13:19:30 Starting - Preparing the instances for training...\n",
      "2024-11-26 13:20:01 Downloading - Downloading input data...\n",
      "2024-11-26 13:20:21 Downloading - Downloading the training image...\n",
      "2024-11-26 13:21:02 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34msed: can't read changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: fatal error: no input files\u001b[0m\n",
      "\u001b[34mcompilation terminated.\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.o: No such file or directory\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,464 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,466 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,467 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,476 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,479 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,481 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,481 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,493 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,493 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,506 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,506 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model-type value vgg16 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2024-11-26 13:21:11,517 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"lr\": 0.005070970373087015,\n",
      "        \"model-type\": \"vgg16\",\n",
      "        \"num-classes\": 133\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"ContentType\": \"application/x-image\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/x-image\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"udacity-sagemaker-hpo-2024-11-26-13-19-14-190\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"hpo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"hpo.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":32,\"lr\":0.005070970373087015,\"model-type\":\"vgg16\",\"num-classes\":133}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=hpo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=hpo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"lr\":0.005070970373087015,\"model-type\":\"vgg16\",\"num-classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"udacity-sagemaker-hpo-2024-11-26-13-19-14-190\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"hpo\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"hpo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--lr\",\"0.005070970373087015\",\"--model-type\",\"vgg16\",\"--num-classes\",\"133\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.005070970373087015\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL-TYPE=vgg16\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-CLASSES=133\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 hpo.py --batch-size 32 --lr 0.005070970373087015 --model-type vgg16 --num-classes 133\u001b[0m\n",
      "\u001b[34m-> Selected model type: vgg16\u001b[0m\n",
      "\u001b[34m-> Loading pretrained model...\u001b[0m\n",
      "\u001b[34m-> Freezing pre-trained model layers...\u001b[0m\n",
      "\u001b[34m-> Replacing pre-trained model classifier with 133 classes...\u001b[0m\n",
      "\u001b[34m[2024-11-26 13:21:15.320 ip-10-0-113-225.ec2.internal:19 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-26 13:21:15.320 ip-10-0-113-225.ec2.internal:19 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-26 13:21:15.320 ip-10-0-113-225.ec2.internal:19 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-26 13:21:15.320 ip-10-0-113-225.ec2.internal:19 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m************************************************************\u001b[0m\n",
      "\u001b[34m-> USING DEBUGER/PROFILER...\u001b[0m\n",
      "\u001b[34m-> Using cross_entropy loss criterion...\u001b[0m\n",
      "\u001b[34m-> Using Adadelta optimizer...\u001b[0m\n",
      "\u001b[34m-> Creating custom data loaders...\u001b[0m\n",
      "\u001b[34m************************************************************\u001b[0m\n",
      "\u001b[34m-> Starting model training...\u001b[0m\n",
      "\u001b[34m[2024-11-26 13:21:15.898 ip-10-0-113-225.ec2.internal:19 INFO hook.py:398] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-26 13:21:15.900 ip-10-0-113-225.ec2.internal:19 INFO hook.py:461] Hook is writing from the hook with pid: 19\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/64 (0%)]#011Loss: 4.637352\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5717, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/64 (0%)]#011Loss: 4.639378\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5657, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/64 (0%)]#011Loss: 4.661213\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5596, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/64 (0%)]#011Loss: 4.720096\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5534, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/64 (0%)]#011Loss: 4.650385\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5473, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/64 (0%)]#011Loss: 4.474475\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5412, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/64 (0%)]#011Loss: 4.541056\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5351, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [0/64 (0%)]#011Loss: 4.345450\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5289, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [0/64 (0%)]#011Loss: 4.467076\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5226, Accuracy: 1/8 (12%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [0/64 (0%)]#011Loss: 4.356894\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5164, Accuracy: 1/8 (12%)\u001b[0m\n",
      "\u001b[34m-> TorchScript model saved to /opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34m-> TorchScript model loaded successfully for verification.\u001b[0m\n",
      "\u001b[34m-> TorchScript model verification successful: Forward pass completed.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/528M [00:00<?, ?B/s]#015  4%|▍         | 21.3M/528M [00:00<00:02, 222MB/s]#015  9%|▉         | 49.5M/528M [00:00<00:01, 265MB/s]#015 16%|█▋        | 86.6M/528M [00:00<00:01, 322MB/s]#015 24%|██▎       | 125M/528M [00:00<00:01, 354MB/s] #015 31%|███       | 162M/528M [00:00<00:01, 367MB/s]#015 38%|███▊      | 201M/528M [00:00<00:00, 380MB/s]#015 45%|████▌     | 239M/528M [00:00<00:00, 388MB/s]#015 53%|█████▎    | 278M/528M [00:00<00:00, 394MB/s]#015 60%|█████▉    | 316M/528M [00:00<00:00, 395MB/s]#015 67%|██████▋   | 355M/528M [00:01<00:00, 399MB/s]#015 75%|███████▍  | 394M/528M [00:01<00:00, 402MB/s]#015 82%|████████▏ | 433M/528M [00:01<00:00, 404MB/s]#015 89%|████████▉ | 472M/528M [00:01<00:00, 402MB/s]#015 97%|█████████▋| 510M/528M [00:01<00:00, 374MB/s]#015100%|██████████| 528M/528M [00:01<00:00, 375MB/s]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:06,  6.72s/it]#0152it [00:12,  6.43s/it]#0152it [00:12,  6.48s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.38s/it]#0152it [00:13,  6.70s/it]#0152it [00:13,  6.83s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.38s/it]#0152it [00:13,  6.67s/it]#0152it [00:13,  6.82s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.59s/it]#0152it [00:13,  6.78s/it]#0152it [00:13,  6.93s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.32s/it]#0152it [00:13,  6.65s/it]#0152it [00:13,  6.79s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.29s/it]#0152it [00:13,  6.63s/it]#0152it [00:13,  6.77s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.26s/it]#0152it [00:14,  7.09s/it]#0152it [00:14,  7.15s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.56s/it]#0152it [00:13,  6.76s/it]#0152it [00:13,  6.91s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.29s/it]#0152it [00:13,  6.64s/it]#0152it [00:13,  6.78s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:07,  7.29s/it]#0152it [00:13,  6.64s/it]#0152it [00:13,  6.78s/it]\u001b[0m\n",
      "\u001b[34m2024-11-26 13:23:56,532 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-26 13:24:03 Uploading - Uploading generated training model\n",
      "2024-11-26 13:24:26 Completed - Training job completed\n",
      "Training seconds: 265\n",
      "Billable seconds: 265\n"
     ]
    }
   ],
   "source": [
    "estimator=Estimator(\n",
    "    image_uri='598308907998.dkr.ecr.us-east-1.amazonaws.com/udacity-sagemaker-hpo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "estimator.fit(inputs=model_inputs, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7e61f-8be3-4f07-826e-06191f90414f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Get the latest training job name\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training Job Name: {training_job_name}\")\n",
    "\n",
    "# Get the model artifact location from the training job details\n",
    "response = sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "model_artifact = response[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(f\"Model Artifact Location: {model_artifact}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc42542-52b6-499e-b15e-38580aefd4dd",
   "metadata": {},
   "source": [
    "# Testing Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fc2e3bb-0705-4987-9333-71453dcb2584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artifact,  # Use the artifact location from the training job\n",
    "    role=estimator.role,       # Use the role from your estimator\n",
    "    entry_point=\"image/inference.py\",\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py3\",\n",
    "    image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.8.1-cpu-py36-ubuntu18.04\",  # PyTorch-Inference image\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69623137-c2b8-411e-b973-317986a06591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-598308907998/udacity-sagemaker-hpo-2024-11-24-20-20-00-150/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-598308907998/pytorch-inference-2024-11-24-20-26-25-124/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-24-20-26-29-479\n"
     ]
    }
   ],
   "source": [
    "transformer = pytorch_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=\"s3://udacity-deeplearning-project/inference/\",  # S3 location for output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9375d00c-5d9e-4add-879a-f74929ec9a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: pytorch-inference-2024-11-24-20-26-32-239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34m2024-11-24 20:31:35,030 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:35,237 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.4.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 2\u001b[0m\n",
      "\u001b[34mMax heap size: 952 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 2\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:35,248 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:35,286 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,405 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,429 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,677 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,678 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,689 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,250 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,482 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,486 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.32533645629883|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,487 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.539794921875|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,487 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,488 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6570.9375|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,488 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:798.8828125|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,489 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:14.3|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,741 [INFO ] W-9000-model_1-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,742 [INFO ] W-9000-model_1-stdout MODEL_LOG - [PID]42\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,742 [INFO ] W-9000-model_1-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,744 [INFO ] W-9000-model_1-stdout MODEL_LOG - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,750 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,781 [INFO ] W-9000-model_1-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,814 [INFO ] W-9001-model_1-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1-stdout MODEL_LOG - [PID]43\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1-stdout MODEL_LOG - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,821 [INFO ] W-9001-model_1-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,347 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 490\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,348 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1930|#Level:Host|#hostname:42a730c6c470,timestamp:1732480298\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,361 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:49|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,436 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 532\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,437 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:2022|#Level:Host|#hostname:42a730c6c470,timestamp:1732480298\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,437 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:121|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,254 [INFO ] pool-1-thread-3 ACCESS_LOG - /169.254.255.130:55842 \"GET /ping HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,255 [INFO ] pool-1-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:55856 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:181.33|#ModelName:model,Level:Model|#hostname:42a730c6c470,requestID:6f24d8c2-4e79-42ed-a5b7-8c7a7cf096ca,timestamp:1732480303\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 182\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:55870 \"POST /invocations HTTP/1.1\" 200 196\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,254 [INFO ] pool-1-thread-3 ACCESS_LOG - /169.254.255.130:55842 \"GET /ping HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,255 [INFO ] pool-1-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:55856 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:181.33|#ModelName:model,Level:Model|#hostname:42a730c6c470,requestID:6f24d8c2-4e79-42ed-a5b7-8c7a7cf096ca,timestamp:1732480303\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 182\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:55870 \"POST /invocations HTTP/1.1\" 200 196\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[32m2024-11-24T20:31:43.312:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "Batch transform completed. Check the output in the specified S3 bucket.\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=\"s3://udacity-deeplearning-project/sample/data/batch/\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(\"Batch transform completed. Check the output in the specified S3 bucket.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ce707-3d47-4a44-aa0e-784abd182860",
   "metadata": {
    "tags": []
   },
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
