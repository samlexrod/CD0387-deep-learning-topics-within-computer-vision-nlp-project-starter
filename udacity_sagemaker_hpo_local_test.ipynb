{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "740fe431-f01d-44ae-9ea6-add181724216",
   "metadata": {},
   "source": [
    "# Save sample data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eea1e1d-c037-42d3-b6f3-0805f259f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:05<00:00, 13.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# List all objects helper internal function\n",
    "def list_all_objects(bucket, prefix):\n",
    "    # Create a paginator for list_objects_v2\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "\n",
    "    # Use the paginator to iterate through all pages\n",
    "    all_objects = []\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        if 'Contents' in page:\n",
    "            all_objects.extend(page['Contents'])\n",
    "\n",
    "    return all_objects\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "prefix = 'data'\n",
    "sample_prefix = 'sample'\n",
    "\n",
    "all_files = list_all_objects(bucket, prefix)\n",
    "\n",
    "sample_files = [file_meta for file_meta in all_files if '001.Affenpinscher' in file_meta.get(\"Key\")]\n",
    "\n",
    "for file_meta in tqdm(sample_files):\n",
    "    key = file_meta.get(\"Key\")\n",
    "    \n",
    "    # Move the data from s3 to a different prefix\n",
    "    dirname = os.path.dirname(key)\n",
    "    if dirname:\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "    s3.download_file(bucket, key, key)\n",
    "    # s3.copy_object(\n",
    "    #     Bucket=bucket,\n",
    "    #     CopySource=f\"{bucket}/{key}\",\n",
    "    #     Key=f\"{sample_prefix}/{key}\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201b549-bd17-499a-8a6f-05752ef5cb08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Estimator Locally Prior to Deployment to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87553aa0-2f98-4f0a-b3fb-e2dd11ec3053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "sha256:5fa8168c9528971ea97c05933b6159a4081fdd235c43dec2812ddbb6e3e3e736\n",
      "REPOSITORY              TAG       IMAGE ID       CREATED                  SIZE\n",
      "udacity-sagemaker-hpo   latest    5fa8168c9528   Less than a second ago   3.92GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: udacity-sagemaker-hpo-2024-11-24-15-40-31-299\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-31tzo:\n",
      "    command: train\n",
      "    container_name: azv89rbpcz-algo-1-31tzo\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: udacity-sagemaker-hpo\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-31tzo\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpjhz50srn/algo-1-31tzo/input:/opt/ml/input\n",
      "    - /tmp/tmpjhz50srn/algo-1-31tzo/output:/opt/ml/output\n",
      "    - /tmp/tmpjhz50srn/algo-1-31tzo/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpjhz50srn/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter/data/test:/opt/ml/input/data/train\n",
      "    - /home/ec2-user/SageMaker/CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter/data/valid:/opt/ml/input/data/test\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpjhz50srn/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Container azv89rbpcz-algo-1-31tzo  Creating\n",
      " Container azv89rbpcz-algo-1-31tzo  Created\n",
      "Attaching to azv89rbpcz-algo-1-31tzo\n",
      "azv89rbpcz-algo-1-31tzo  | sed: can't read changehostname.c: No such file or directory\n",
      "azv89rbpcz-algo-1-31tzo  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kchangehostname.c: No such file or directory\n",
      "azv89rbpcz-algo-1-31tzo  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
      "azv89rbpcz-algo-1-31tzo  | compilation terminated.\n",
      "azv89rbpcz-algo-1-31tzo  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kchangehostname.o: No such file or directory\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,083 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,086 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,100 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,115 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,119 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,136 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,152 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:39,166 sagemaker-training-toolkit INFO     Invoking user script\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | Training Env:\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | {\n",
      "azv89rbpcz-algo-1-31tzo  |     \"additional_framework_parameters\": {},\n",
      "azv89rbpcz-algo-1-31tzo  |     \"channel_input_dirs\": {\n",
      "azv89rbpcz-algo-1-31tzo  |         \"train\": \"/opt/ml/input/data/train\",\n",
      "azv89rbpcz-algo-1-31tzo  |         \"test\": \"/opt/ml/input/data/test\"\n",
      "azv89rbpcz-algo-1-31tzo  |     },\n",
      "azv89rbpcz-algo-1-31tzo  |     \"current_host\": \"algo-1-31tzo\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"hosts\": [\n",
      "azv89rbpcz-algo-1-31tzo  |         \"algo-1-31tzo\"\n",
      "azv89rbpcz-algo-1-31tzo  |     ],\n",
      "azv89rbpcz-algo-1-31tzo  |     \"hyperparameters\": {\n",
      "azv89rbpcz-algo-1-31tzo  |         \"num-classes\": 133,\n",
      "azv89rbpcz-algo-1-31tzo  |         \"batch-size\": 32,\n",
      "azv89rbpcz-algo-1-31tzo  |         \"lr\": 0.005070970373087015\n",
      "azv89rbpcz-algo-1-31tzo  |     },\n",
      "azv89rbpcz-algo-1-31tzo  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"input_data_config\": {\n",
      "azv89rbpcz-algo-1-31tzo  |         \"train\": {\n",
      "azv89rbpcz-algo-1-31tzo  |             \"TrainingInputMode\": \"File\"\n",
      "azv89rbpcz-algo-1-31tzo  |         },\n",
      "azv89rbpcz-algo-1-31tzo  |         \"test\": {\n",
      "azv89rbpcz-algo-1-31tzo  |             \"TrainingInputMode\": \"File\"\n",
      "azv89rbpcz-algo-1-31tzo  |         }\n",
      "azv89rbpcz-algo-1-31tzo  |     },\n",
      "azv89rbpcz-algo-1-31tzo  |     \"input_dir\": \"/opt/ml/input\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"is_master\": true,\n",
      "azv89rbpcz-algo-1-31tzo  |     \"job_name\": \"udacity-sagemaker-hpo-2024-11-24-15-40-31-299\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"log_level\": 20,\n",
      "azv89rbpcz-algo-1-31tzo  |     \"master_hostname\": \"algo-1-31tzo\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"model_dir\": \"/opt/ml/model\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"module_dir\": \"/opt/ml/code\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"module_name\": \"hpo\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"network_interface_name\": \"eth0\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"num_cpus\": 2,\n",
      "azv89rbpcz-algo-1-31tzo  |     \"num_gpus\": 0,\n",
      "azv89rbpcz-algo-1-31tzo  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"output_dir\": \"/opt/ml/output\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "azv89rbpcz-algo-1-31tzo  |     \"resource_config\": {\n",
      "azv89rbpcz-algo-1-31tzo  |         \"current_host\": \"algo-1-31tzo\",\n",
      "azv89rbpcz-algo-1-31tzo  |         \"hosts\": [\n",
      "azv89rbpcz-algo-1-31tzo  |             \"algo-1-31tzo\"\n",
      "azv89rbpcz-algo-1-31tzo  |         ]\n",
      "azv89rbpcz-algo-1-31tzo  |     },\n",
      "azv89rbpcz-algo-1-31tzo  |     \"user_entry_point\": \"hpo.py\"\n",
      "azv89rbpcz-algo-1-31tzo  | }\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | Environment variables:\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | SM_HOSTS=[\"algo-1-31tzo\"]\n",
      "azv89rbpcz-algo-1-31tzo  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "azv89rbpcz-algo-1-31tzo  | SM_HPS={\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133}\n",
      "azv89rbpcz-algo-1-31tzo  | SM_USER_ENTRY_POINT=hpo.py\n",
      "azv89rbpcz-algo-1-31tzo  | SM_FRAMEWORK_PARAMS={}\n",
      "azv89rbpcz-algo-1-31tzo  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-31tzo\",\"hosts\":[\"algo-1-31tzo\"]}\n",
      "azv89rbpcz-algo-1-31tzo  | SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "azv89rbpcz-algo-1-31tzo  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "azv89rbpcz-algo-1-31tzo  | SM_CHANNELS=[\"test\",\"train\"]\n",
      "azv89rbpcz-algo-1-31tzo  | SM_CURRENT_HOST=algo-1-31tzo\n",
      "azv89rbpcz-algo-1-31tzo  | SM_MODULE_NAME=hpo\n",
      "azv89rbpcz-algo-1-31tzo  | SM_LOG_LEVEL=20\n",
      "azv89rbpcz-algo-1-31tzo  | SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "azv89rbpcz-algo-1-31tzo  | SM_INPUT_DIR=/opt/ml/input\n",
      "azv89rbpcz-algo-1-31tzo  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "azv89rbpcz-algo-1-31tzo  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "azv89rbpcz-algo-1-31tzo  | SM_NUM_CPUS=2\n",
      "azv89rbpcz-algo-1-31tzo  | SM_NUM_GPUS=0\n",
      "azv89rbpcz-algo-1-31tzo  | SM_MODEL_DIR=/opt/ml/model\n",
      "azv89rbpcz-algo-1-31tzo  | SM_MODULE_DIR=/opt/ml/code\n",
      "azv89rbpcz-algo-1-31tzo  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-31tzo\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-31tzo\"],\"hyperparameters\":{\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"udacity-sagemaker-hpo-2024-11-24-15-40-31-299\",\"log_level\":20,\"master_hostname\":\"algo-1-31tzo\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"hpo\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-31tzo\",\"hosts\":[\"algo-1-31tzo\"]},\"user_entry_point\":\"hpo.py\"}\n",
      "azv89rbpcz-algo-1-31tzo  | SM_USER_ARGS=[\"--batch-size\",\"32\",\"--lr\",\"0.005070970373087015\",\"--num-classes\",\"133\"]\n",
      "azv89rbpcz-algo-1-31tzo  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "azv89rbpcz-algo-1-31tzo  | SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "azv89rbpcz-algo-1-31tzo  | SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "azv89rbpcz-algo-1-31tzo  | SM_HP_NUM-CLASSES=133\n",
      "azv89rbpcz-algo-1-31tzo  | SM_HP_BATCH-SIZE=32\n",
      "azv89rbpcz-algo-1-31tzo  | SM_HP_LR=0.005070970373087015\n",
      "azv89rbpcz-algo-1-31tzo  | PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | Invoking script with the following command:\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | /opt/conda/bin/python3.6 hpo.py --batch-size 32 --lr 0.005070970373087015 --num-classes 133\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | Traceback (most recent call last):\n",
      "azv89rbpcz-algo-1-31tzo  |   File \"hpo.py\", line 24, in <module>\n",
      "azv89rbpcz-algo-1-31tzo  |     from smdebug.profiler.utils import str2bool\n",
      "azv89rbpcz-algo-1-31tzo  | ModuleNotFoundError: No module named 'smdebug.profiler.utils'\n",
      "azv89rbpcz-algo-1-31tzo  | \n",
      "azv89rbpcz-algo-1-31tzo  | 2024-11-24 15:40:40,472 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "azv89rbpcz-algo-1-31tzo  | Command \"/opt/conda/bin/python3.6 hpo.py --batch-size 32 --lr 0.005070970373087015 --num-classes 133\"\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "azv89rbpcz-algo-1-31tzo  | Traceback (most recent call last):\n",
      "azv89rbpcz-algo-1-31tzo  |   File \"hpo.py\", line 24, in <module>\n",
      "azv89rbpcz-algo-1-31tzo  |     from smdebug.profiler.utils import str2bool\n",
      "azv89rbpcz-algo-1-31tzo  | ModuleNotFoundError: No module named 'smdebug.profiler.utils'\n",
      "azv89rbpcz-algo-1-31tzo exited with code 1\n",
      "Aborting on container exit...\n",
      " Container azv89rbpcz-algo-1-31tzo  Stopping\n",
      " Container azv89rbpcz-algo-1-31tzo  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:sagemaker:Please check the troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html#sagemaker-python-sdk-troubleshooting-create-training-job\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmpjhz50srn/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']. Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     22\u001b[0m estimator\u001b[38;5;241m=\u001b[39mEstimator(\n\u001b[1;32m     23\u001b[0m     image_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mudacity-sagemaker-hpo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m     role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     hyperparameters\u001b[38;5;241m=\u001b[39mhyperparameters\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile://./data/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile://./data/valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m }\n\u001b[0;32m---> 36\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/estimator.py:1369\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_training(job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[1;32m   1368\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TrainingJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1371\u001b[0m forward_to_mlflow_tracking_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/estimator.py:2498\u001b[0m, in \u001b[0;36m_TrainingJob.start_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   2495\u001b[0m train_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_args(estimator, inputs, experiment_config)\n\u001b[1;32m   2497\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain args after processing defaults: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, train_args)\n\u001b[0;32m-> 2498\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(estimator\u001b[38;5;241m.\u001b[39msagemaker_session, estimator\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/session.py:1055\u001b[0m, in \u001b[0;36mSession.train\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, training_image_config, infra_check_config, container_entry_point, container_arguments, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy, remote_debug_config, session_chaining_config)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m   1051\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the troubleshooting guide for common errors: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, troubleshooting\n\u001b[1;32m   1052\u001b[0m         )\n\u001b[1;32m   1053\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m-> 1055\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/session.py:6606\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   6589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   6590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6591\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6594\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   6595\u001b[0m ):\n\u001b[1;32m   6596\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   6597\u001b[0m \n\u001b[1;32m   6598\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6604\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   6605\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/session.py:1053\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1046\u001b[0m troubleshooting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#sagemaker-python-sdk-troubleshooting-create-training-job\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m )\n\u001b[1;32m   1050\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the troubleshooting guide for common errors: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, troubleshooting\n\u001b[1;32m   1052\u001b[0m )\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/session.py:1044\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating training-job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m   1043\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_training_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1046\u001b[0m     troubleshooting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#sagemaker-python-sdk-troubleshooting-create-training-job\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py:149\u001b[0m, in \u001b[0;36m_telemetry_emitter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m caught_ex:\n\u001b[0;32m--> 149\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m caught_ex\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response  \u001b[38;5;66;03m# pylint: disable=W0150\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py:120\u001b[0m, in \u001b[0;36m_telemetry_emitter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m start_timer \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# Call the original function\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     stop_timer \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    122\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m stop_timer \u001b[38;5;241m-\u001b[39m start_timer\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/local/local_session.py:216\u001b[0m, in \u001b[0;36mLocalSagemakerClient.create_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, Environment, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    215\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training job\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m \u001b[43mtraining_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mInputDataConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutputDataConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEnvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainingJobName\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m LocalSagemakerClient\u001b[38;5;241m.\u001b[39m_training_jobs[TrainingJobName] \u001b[38;5;241m=\u001b[39m training_job\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/local/entities.py:252\u001b[0m, in \u001b[0;36m_LocalTrainingJob.start\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_TRAINING\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment \u001b[38;5;241m=\u001b[39m environment\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_artifacts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_COMPLETED\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/local/image.py:313\u001b[0m, in \u001b[0;36m_SageMakerContainer.train\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    308\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[1;32m    309\u001b[0m     compose_command, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT\n\u001b[1;32m    310\u001b[0m )\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m     \u001b[43m_stream_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     artifacts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_artifacts(compose_data, output_data_config, job_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/sagemaker/local/image.py:1020\u001b[0m, in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     exit_code \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exit_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m130\u001b[39m]:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess\u001b[38;5;241m.\u001b[39margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Process exited with code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexit_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exit_code\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmpjhz50srn/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']. Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(['sh', 'docker-build.sh'])\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "sample_prefix = 'sample'\n",
    "\n",
    "hyperparameters = {\n",
    "    'num-classes': 133,\n",
    "    'batch-size': 32,\n",
    "    'lr': 0.005070970373087015\n",
    "}\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "s3_output_location = f\"s3://{bucket}/outputs\"\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='udacity-sagemaker-hpo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "model_inputs = {\n",
    "    \"train\": \"file://./data/test\",\n",
    "    \"test\": \"file://./data/valid\"\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=model_inputs, logs=True ,wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d3514-bc1c-40d5-a000-97292ccb17c8",
   "metadata": {},
   "source": [
    "## Testing Deployed Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f43502-7b17-4fa6-bddd-90a3271bb641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push-container.sh: line 1: fg: no job control\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (1/1) FINISHED                                 docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2B                                         0.0s\n",
      "\u001b[0m\u001b[?25hERROR: failed to solve: failed to read dockerfile: open Dockerfile: no such file or directory\n",
      "The push refers to repository [598308907998.dkr.ecr.us-east-1.amazonaws.com/udacity-sagemaker-hpo]\n",
      "\n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B4c4874d4: Preparing \n",
      "\u001b[1Baabbac8e: Preparing \n",
      "\u001b[1B95045e04: Preparing \n",
      "\u001b[1Be9708ca1: Preparing \n",
      "\u001b[1B8f6060c6: Preparing \n",
      "\u001b[1Ba3c12226: Preparing \n",
      "\u001b[1B62daa95e: Preparing \n",
      "\u001b[1B8fe1cb59: Preparing \n",
      "\u001b[1B061a5b0d: Preparing \n",
      "\u001b[1B3ff1bf08: Preparing \n",
      "\u001b[1Bfc0e8a35: Preparing \n",
      "\u001b[1B6a8aee3d: Preparing \n",
      "\u001b[1Be27443e4: Preparing \n",
      "\u001b[1Bd2b930fc: Preparing \n",
      "\u001b[1Bec0db89a: Preparing \n",
      "\u001b[1B49baa658: Preparing \n",
      "\u001b[16Babbac8e: Pushed lready exists 8MB7A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[18A\u001b[2K\u001b[1A\u001b[2K\u001b[16A\u001b[2Klatest: digest: sha256:c321fc82889081d8d32106de0211933620a705dd45cd47f581c22a99036f6043 size: 4082\n"
     ]
    }
   ],
   "source": [
    "!sh push-container.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070d573d-0e9e-4862-a5c6-384483849ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_inputs = {\n",
    "    \"train\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/{sample_prefix}/data/train/\",\n",
    "        content_type=\"application/x-image\"\n",
    "    ),\n",
    "    \"test\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/{sample_prefix}/data/valid/\",\n",
    "        content_type=\"application/x-image\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db355544-0e4d-424b-b8e7-246a93e08c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'num-classes': 133,\n",
    "    'batch-size': 32,\n",
    "    'lr': 0.005070970373087015\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ace2c8-ca83-4f3f-93a2-16d0126e1cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: udacity-sagemaker-hpo-2024-11-23-20-04-48-449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-23 20:04:51 Starting - Starting the training job\n",
      "2024-11-23 20:04:51 Pending - Training job waiting for capacity.........\n",
      "2024-11-23 20:06:02 Pending - Preparing the instances for training...\n",
      "2024-11-23 20:06:43 Downloading - Downloading input data...\n",
      "2024-11-23 20:07:03 Downloading - Downloading the training image...\n",
      "2024-11-23 20:07:54 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34msed: can't read changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: fatal error: no input files\u001b[0m\n",
      "\u001b[34mcompilation terminated.\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.o: No such file or directory\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2024-11-23 20:08:06,517 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2024-11-23 20:08:06,550 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-23 20:08:06,552 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2024-11-23 20:08:06,648 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"lr\": 0.005070970373087015,\n",
      "        \"num-classes\": 133\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"ContentType\": \"application/x-image\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/x-image\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"udacity-sagemaker-hpo-2024-11-23-20-04-48-449\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"hpo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"hpo.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=hpo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=hpo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"udacity-sagemaker-hpo-2024-11-23-20-04-48-449\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"hpo\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"hpo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--lr\",\"0.005070970373087015\",\"--num-classes\",\"133\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.005070970373087015\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-CLASSES=133\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 hpo.py --batch-size 32 --lr 0.005070970373087015 --num-classes 133\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:07.653 ip-10-2-106-227.ec2.internal:25 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:07.883 ip-10-2-106-227.ec2.internal:25 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m-> Loading pretrained model...\u001b[0m\n",
      "\u001b[34m-> Freezing pre-trained model layers...\u001b[0m\n",
      "\u001b[34m-> Replacing pre-trained model classifier with 133 classes...\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:08.523 ip-10-2-106-227.ec2.internal:25 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:08.523 ip-10-2-106-227.ec2.internal:25 INFO hook.py:202] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:08.524 ip-10-2-106-227.ec2.internal:25 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:08.524 ip-10-2-106-227.ec2.internal:25 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m************************************************************\u001b[0m\n",
      "\u001b[34m-> USING DEBUGER/PROFILER...\u001b[0m\n",
      "\u001b[34m-> Using cross_entropy loss criterion...\u001b[0m\n",
      "\u001b[34m-> Using Adadelta optimizer...\u001b[0m\n",
      "\u001b[34m-> Creating custom data loaders...\u001b[0m\n",
      "\u001b[34m************************************************************\u001b[0m\n",
      "\u001b[34m-> Starting model training...\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:09.269 ip-10-2-106-227.ec2.internal:25 INFO hook.py:560] name:fc.weight count_params:68096\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:09.269 ip-10-2-106-227.ec2.internal:25 INFO hook.py:560] name:fc.bias count_params:133\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:09.269 ip-10-2-106-227.ec2.internal:25 INFO hook.py:562] Total Trainable Params: 68229\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:09.269 ip-10-2-106-227.ec2.internal:25 INFO hook.py:422] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-23 20:08:09.273 ip-10-2-106-227.ec2.internal:25 INFO hook.py:485] Hook is writing from the hook with pid: 25\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/64 (0%)]#011Loss: 4.447529\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6052, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/64 (0%)]#011Loss: 4.406153\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5844, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/64 (0%)]#011Loss: 4.395123\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5683, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/64 (0%)]#011Loss: 4.353444\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5550, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/64 (0%)]#011Loss: 4.332447\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5441, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/64 (0%)]#011Loss: 4.305102\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5348, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/64 (0%)]#011Loss: 4.269059\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5269, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [0/64 (0%)]#011Loss: 4.239226\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5197, Accuracy: 1/8 (12%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [0/64 (0%)]#011Loss: 4.205338\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5135, Accuracy: 1/8 (12%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [0/64 (0%)]#011Loss: 4.187312\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.5080, Accuracy: 1/8 (12%)\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 53%|█████▎    | 23.6M/44.7M [00:00<00:00, 247MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 257MB/s]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.16s/it]#0152it [00:01,  1.08it/s]#0152it [00:01,  1.04it/s]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.32s/it]#0152it [00:02,  1.00it/s]#0152it [00:02,  1.05s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.35s/it]#0152it [00:02,  1.01s/it]#0152it [00:02,  1.07s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.27s/it]#0152it [00:02,  1.05it/s]#0152it [00:02,  1.01s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.31s/it]#0152it [00:02,  1.02it/s]#0152it [00:02,  1.04s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.39s/it]#0152it [00:02,  1.01s/it]#0152it [00:02,  1.07s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.29s/it]#0152it [00:02,  1.02it/s]#0152it [00:02,  1.04s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.26s/it]#0152it [00:02,  1.03it/s]#0152it [00:02,  1.02s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.42s/it]#0152it [00:02,  1.01s/it]#0152it [00:02,  1.09s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.29s/it]#0152it [00:02,  1.04it/s]#0152it [00:02,  1.02s/it]\u001b[0m\n",
      "\u001b[34m2024-11-23 20:08:34,991 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-23 20:08:52 Uploading - Uploading generated training model\n",
      "2024-11-23 20:08:52 Completed - Training job completed\n",
      "Training seconds: 130\n",
      "Billable seconds: 130\n"
     ]
    }
   ],
   "source": [
    "estimator=Estimator(\n",
    "    image_uri='598308907998.dkr.ecr.us-east-1.amazonaws.com/udacity-sagemaker-hpo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "estimator.fit(inputs=model_inputs, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ce707-3d47-4a44-aa0e-784abd182860",
   "metadata": {
    "tags": []
   },
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
