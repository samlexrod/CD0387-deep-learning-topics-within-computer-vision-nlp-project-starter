{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "740fe431-f01d-44ae-9ea6-add181724216",
   "metadata": {},
   "source": [
    "# Save sample data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eea1e1d-c037-42d3-b6f3-0805f259f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:06<00:00, 12.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# List all objects helper internal function\n",
    "def list_all_objects(bucket, prefix):\n",
    "    # Create a paginator for list_objects_v2\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "\n",
    "    # Use the paginator to iterate through all pages\n",
    "    all_objects = []\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        if 'Contents' in page:\n",
    "            all_objects.extend(page['Contents'])\n",
    "\n",
    "    return all_objects\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "prefix = 'data'\n",
    "sample_prefix = 'sample'\n",
    "\n",
    "all_files = list_all_objects(bucket, prefix)\n",
    "\n",
    "sample_files = [file_meta for file_meta in all_files if '001.Affenpinscher' in file_meta.get(\"Key\")]\n",
    "\n",
    "for file_meta in tqdm(sample_files):\n",
    "    key = file_meta.get(\"Key\")\n",
    "    \n",
    "    # Move the data from s3 to a different prefix\n",
    "    dirname = os.path.dirname(key)\n",
    "    if dirname:\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "    s3.download_file(bucket, key, key)\n",
    "    # s3.copy_object(\n",
    "    #     Bucket=bucket,\n",
    "    #     CopySource=f\"{bucket}/{key}\",\n",
    "    #     Key=f\"{sample_prefix}/{key}\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201b549-bd17-499a-8a6f-05752ef5cb08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Estimator Locally Prior to Deployment to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87553aa0-2f98-4f0a-b3fb-e2dd11ec3053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:6e54afc9f27d48bdfc45a27f9662fa1a075ae00ad672a43792131965265c53f5\n",
      "REPOSITORY                                                           TAG       IMAGE ID       CREATED                  SIZE\n",
      "udacity-sagemaker-hpo                                                latest    6e54afc9f27d   Less than a second ago   3.92GB\n",
      "598308907998.dkr.ecr.us-east-1.amazonaws.com/udacity-sagemaker-hpo   latest    a351c2adb476   33 minutes ago           3.92GB\n",
      "<none>                                                               <none>    6006234684a7   34 minutes ago           3.92GB\n",
      "<none>                                                               <none>    fba9a75aee2f   37 minutes ago           3.92GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: udacity-sagemaker-hpo-2024-11-24-20-19-25-597\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-0hih5:\n",
      "    command: train\n",
      "    container_name: m4yq0lzjnr-algo-1-0hih5\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: udacity-sagemaker-hpo\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-0hih5\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpq2xks88y/algo-1-0hih5/output:/opt/ml/output\n",
      "    - /tmp/tmpq2xks88y/algo-1-0hih5/input:/opt/ml/input\n",
      "    - /tmp/tmpq2xks88y/algo-1-0hih5/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpq2xks88y/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/ec2-user/SageMaker/CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter/data/test:/opt/ml/input/data/train\n",
      "    - /home/ec2-user/SageMaker/CD0387-deep-learning-topics-within-computer-vision-nlp-project-starter/data/valid:/opt/ml/input/data/test\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpq2xks88y/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Container m4yq0lzjnr-algo-1-0hih5  Creating\n",
      " Container m4yq0lzjnr-algo-1-0hih5  Created\n",
      "Attaching to m4yq0lzjnr-algo-1-0hih5\n",
      "m4yq0lzjnr-algo-1-0hih5  | sed: can't read changehostname.c: No such file or directory\n",
      "m4yq0lzjnr-algo-1-0hih5  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kchangehostname.c: No such file or directory\n",
      "m4yq0lzjnr-algo-1-0hih5  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
      "m4yq0lzjnr-algo-1-0hih5  | compilation terminated.\n",
      "m4yq0lzjnr-algo-1-0hih5  | \u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kchangehostname.o: No such file or directory\n",
      "m4yq0lzjnr-algo-1-0hih5  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,432 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,435 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,447 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,458 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,461 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,476 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,491 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:26,504 sagemaker-training-toolkit INFO     Invoking user script\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Training Env:\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | {\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"additional_framework_parameters\": {},\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"channel_input_dirs\": {\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"train\": \"/opt/ml/input/data/train\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"test\": \"/opt/ml/input/data/test\"\n",
      "m4yq0lzjnr-algo-1-0hih5  |     },\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"current_host\": \"algo-1-0hih5\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"hosts\": [\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"algo-1-0hih5\"\n",
      "m4yq0lzjnr-algo-1-0hih5  |     ],\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"hyperparameters\": {\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"num-classes\": 133,\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"batch-size\": 32,\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"lr\": 0.005070970373087015\n",
      "m4yq0lzjnr-algo-1-0hih5  |     },\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"input_data_config\": {\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"train\": {\n",
      "m4yq0lzjnr-algo-1-0hih5  |             \"TrainingInputMode\": \"File\"\n",
      "m4yq0lzjnr-algo-1-0hih5  |         },\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"test\": {\n",
      "m4yq0lzjnr-algo-1-0hih5  |             \"TrainingInputMode\": \"File\"\n",
      "m4yq0lzjnr-algo-1-0hih5  |         }\n",
      "m4yq0lzjnr-algo-1-0hih5  |     },\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"input_dir\": \"/opt/ml/input\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"is_master\": true,\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"job_name\": \"udacity-sagemaker-hpo-2024-11-24-20-19-25-597\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"log_level\": 20,\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"master_hostname\": \"algo-1-0hih5\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"model_dir\": \"/opt/ml/model\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"module_dir\": \"/opt/ml/code\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"module_name\": \"hpo\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"network_interface_name\": \"eth0\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"num_cpus\": 2,\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"num_gpus\": 0,\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"output_dir\": \"/opt/ml/output\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"resource_config\": {\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"current_host\": \"algo-1-0hih5\",\n",
      "m4yq0lzjnr-algo-1-0hih5  |         \"hosts\": [\n",
      "m4yq0lzjnr-algo-1-0hih5  |             \"algo-1-0hih5\"\n",
      "m4yq0lzjnr-algo-1-0hih5  |         ]\n",
      "m4yq0lzjnr-algo-1-0hih5  |     },\n",
      "m4yq0lzjnr-algo-1-0hih5  |     \"user_entry_point\": \"hpo.py\"\n",
      "m4yq0lzjnr-algo-1-0hih5  | }\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Environment variables:\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_HOSTS=[\"algo-1-0hih5\"]\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_HPS={\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133}\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_USER_ENTRY_POINT=hpo.py\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_FRAMEWORK_PARAMS={}\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-0hih5\",\"hosts\":[\"algo-1-0hih5\"]}\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_CHANNELS=[\"test\",\"train\"]\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_CURRENT_HOST=algo-1-0hih5\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_MODULE_NAME=hpo\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_LOG_LEVEL=20\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_INPUT_DIR=/opt/ml/input\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_NUM_CPUS=2\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_NUM_GPUS=0\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_MODEL_DIR=/opt/ml/model\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_MODULE_DIR=/opt/ml/code\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-0hih5\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-0hih5\"],\"hyperparameters\":{\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"udacity-sagemaker-hpo-2024-11-24-20-19-25-597\",\"log_level\":20,\"master_hostname\":\"algo-1-0hih5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"hpo\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-0hih5\",\"hosts\":[\"algo-1-0hih5\"]},\"user_entry_point\":\"hpo.py\"}\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_USER_ARGS=[\"--batch-size\",\"32\",\"--lr\",\"0.005070970373087015\",\"--num-classes\",\"133\"]\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_HP_NUM-CLASSES=133\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_HP_BATCH-SIZE=32\n",
      "m4yq0lzjnr-algo-1-0hih5  | SM_HP_LR=0.005070970373087015\n",
      "m4yq0lzjnr-algo-1-0hih5  | PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Invoking script with the following command:\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | /opt/conda/bin/python3.6 hpo.py --batch-size 32 --lr 0.005070970373087015 --num-classes 133\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | -> Loading pretrained model...\n",
      "m4yq0lzjnr-algo-1-0hih5  | -> Freezing pre-trained model layers...\n",
      "m4yq0lzjnr-algo-1-0hih5  | -> Replacing pre-trained model classifier with 133 classes...\n",
      "m4yq0lzjnr-algo-1-0hih5  | ************************************************************\n",
      "m4yq0lzjnr-algo-1-0hih5  | -> USING LOCAL RUN...\n",
      "m4yq0lzjnr-algo-1-0hih5  | -> Using cross_entropy loss criterion...\n",
      "m4yq0lzjnr-algo-1-0hih5  | -> Using Adadelta optimizer...\n",
      "m4yq0lzjnr-algo-1-0hih5  | -> Creating custom data loaders...\n",
      "m4yq0lzjnr-algo-1-0hih5  | ************************************************************\n",
      "m4yq0lzjnr-algo-1-0hih5  | -> Starting model training...\n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 1 [0/8 (0%)]\tLoss: 5.313029\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7515, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 2 [0/8 (0%)]\tLoss: 5.299185\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7438, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 3 [0/8 (0%)]\tLoss: 5.285001\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7371, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 4 [0/8 (0%)]\tLoss: 5.270582\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7320, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 5 [0/8 (0%)]\tLoss: 5.255982\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7268, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 6 [0/8 (0%)]\tLoss: 5.241230\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7220, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 7 [0/8 (0%)]\tLoss: 5.226350\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7180, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 8 [0/8 (0%)]\tLoss: 5.211354\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7145, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 9 [0/8 (0%)]\tLoss: 5.196254\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7111, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Train Epoch: 10 [0/8 (0%)]\tLoss: 5.181058\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | Test set: Average loss: 0.7079, Accuracy: 0/8 (0%)\n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | TorchScript model saved to /opt/ml/model/model.pth\n",
      "m4yq0lzjnr-algo-1-0hih5  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "m4yq0lzjnr-algo-1-0hih5  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "m4yq0lzjnr-algo-1-0hih5  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "m4yq0lzjnr-algo-1-0hih5  | ERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "m4yq0lzjnr-algo-1-0hih5  | Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 141MB/s]\n",
      "1it [00:00,  2.05it/s]5  | \n",
      "1it [00:00,  1.89it/s]5  | \n",
      "1it [00:00,  1.89it/s]5  | \n",
      "1it [00:00,  1.82it/s]5  | \n",
      "1it [00:00,  1.89it/s]5  | \n",
      "1it [00:00,  1.93it/s]5  | \n",
      "1it [00:00,  1.92it/s]5  | \n",
      "1it [00:00,  1.92it/s]5  | \n",
      "1it [00:00,  1.90it/s]5  | \n",
      "1it [00:00,  1.88it/s]5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | \n",
      "m4yq0lzjnr-algo-1-0hih5  | 2024-11-24 20:19:40,488 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "m4yq0lzjnr-algo-1-0hih5 exited with code 0\n",
      "Aborting on container exit...\n",
      " Container m4yq0lzjnr-algo-1-0hih5  Stopping\n",
      " Container m4yq0lzjnr-algo-1-0hih5  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmpq2xks88y/algo-1-0hih5 Please remove it manually.\n",
      "INFO:sagemaker.local.image:===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(['sh', 'docker-build.sh'])\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "sample_prefix = 'sample'\n",
    "\n",
    "hyperparameters = {\n",
    "    'num-classes': 133,\n",
    "    'batch-size': 32,\n",
    "    'lr': 0.005070970373087015\n",
    "}\n",
    "\n",
    "bucket = 'udacity-deeplearning-project'\n",
    "s3_output_location = f\"s3://{bucket}/outputs\"\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='udacity-sagemaker-hpo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "model_inputs = {\n",
    "    \"train\": \"file://./data/test\",\n",
    "    \"test\": \"file://./data/valid\"\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=model_inputs, logs=True ,wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d3514-bc1c-40d5-a000-97292ccb17c8",
   "metadata": {},
   "source": [
    "## Testing Deployed Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f43502-7b17-4fa6-bddd-90a3271bb641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "push-container.sh: line 1: fg: no job control\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (1/1) FINISHED                                 docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2B                                         0.0s\n",
      "\u001b[0m\u001b[?25hERROR: failed to solve: failed to read dockerfile: open Dockerfile: no such file or directory\n",
      "The push refers to repository [598308907998.dkr.ecr.us-east-1.amazonaws.com/udacity-sagemaker-hpo]\n",
      "\n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1Bc6a5eeb1: Preparing \n",
      "\u001b[1B0a42ae7f: Preparing \n",
      "\u001b[1B38d8788c: Preparing \n",
      "\u001b[1B95045e04: Preparing \n",
      "\u001b[1Be9708ca1: Preparing \n",
      "\u001b[1B8f6060c6: Preparing \n",
      "\u001b[1Ba3c12226: Preparing \n",
      "\u001b[1B62daa95e: Preparing \n",
      "\u001b[1B8fe1cb59: Preparing \n",
      "\u001b[1B061a5b0d: Preparing \n",
      "\u001b[1B3ff1bf08: Preparing \n",
      "\u001b[1Bfc0e8a35: Preparing \n",
      "\u001b[1B6a8aee3d: Preparing \n",
      "\u001b[1Be27443e4: Preparing \n",
      "\u001b[1Bd2b930fc: Preparing \n",
      "\u001b[1Bec0db89a: Preparing \n",
      "\u001b[1B49baa658: Preparing \n",
      "\u001b[18B6a5eeb1: Pushed lready exists 8kB8A\u001b[2K\u001b[12A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[18A\u001b[2Klatest: digest: sha256:d460214da5f26a5cf09c0d83a507b77e8d2095aa0be1eb467b4808a9056a8c09 size: 4287\n"
     ]
    }
   ],
   "source": [
    "!sh push-container.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "070d573d-0e9e-4862-a5c6-384483849ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_inputs = {\n",
    "    \"train\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/{sample_prefix}/data/train/\",\n",
    "        content_type=\"application/x-image\"\n",
    "    ),\n",
    "    \"test\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/{sample_prefix}/data/valid/\",\n",
    "        content_type=\"application/x-image\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db355544-0e4d-424b-b8e7-246a93e08c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'num-classes': 133,\n",
    "    'batch-size': 32,\n",
    "    'lr': 0.005070970373087015\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78ace2c8-ca83-4f3f-93a2-16d0126e1cdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: udacity-sagemaker-hpo-2024-11-24-20-20-00-150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-24 20:20:00 Starting - Starting the training job...\n",
      "2024-11-24 20:20:27 Starting - Preparing the instances for training...\n",
      "2024-11-24 20:21:05 Downloading - Downloading the training image......\n",
      "2024-11-24 20:21:46 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34msed: can't read changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: fatal error: no input files\u001b[0m\n",
      "\u001b[34mcompilation terminated.\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.o: No such file or directory\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,907 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,909 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,920 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,922 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,924 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,936 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,949 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-24 20:21:52,959 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"lr\": 0.005070970373087015,\n",
      "        \"num-classes\": 133\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"ContentType\": \"application/x-image\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/x-image\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"udacity-sagemaker-hpo-2024-11-24-20-20-00-150\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"hpo\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"hpo.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=hpo.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=hpo\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"lr\":0.005070970373087015,\"num-classes\":133},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"ContentType\":\"application/x-image\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"udacity-sagemaker-hpo-2024-11-24-20-20-00-150\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"hpo\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"hpo.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--lr\",\"0.005070970373087015\",\"--num-classes\",\"133\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.005070970373087015\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-CLASSES=133\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 hpo.py --batch-size 32 --lr 0.005070970373087015 --num-classes 133\u001b[0m\n",
      "\u001b[34m-> Loading pretrained model...\u001b[0m\n",
      "\u001b[34m-> Freezing pre-trained model layers...\u001b[0m\n",
      "\u001b[34m-> Replacing pre-trained model classifier with 133 classes...\u001b[0m\n",
      "\u001b[34m[2024-11-24 20:21:54.523 ip-10-2-90-239.ec2.internal:19 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-24 20:21:54.524 ip-10-2-90-239.ec2.internal:19 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-24 20:21:54.524 ip-10-2-90-239.ec2.internal:19 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-24 20:21:54.524 ip-10-2-90-239.ec2.internal:19 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m************************************************************\u001b[0m\n",
      "\u001b[34m-> USING DEBUGER/PROFILER...\u001b[0m\n",
      "\u001b[34m-> Using cross_entropy loss criterion...\u001b[0m\n",
      "\u001b[34m-> Using Adadelta optimizer...\u001b[0m\n",
      "\u001b[34m-> Creating custom data loaders...\u001b[0m\n",
      "\u001b[34m************************************************************\u001b[0m\n",
      "\u001b[34m-> Starting model training...\u001b[0m\n",
      "\u001b[34m[2024-11-24 20:21:55.103 ip-10-2-90-239.ec2.internal:19 INFO hook.py:398] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-24 20:21:55.105 ip-10-2-90-239.ec2.internal:19 INFO hook.py:461] Hook is writing from the hook with pid: 19\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/64 (0%)]#011Loss: 5.351954\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6664, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/64 (0%)]#011Loss: 5.314866\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6648, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/64 (0%)]#011Loss: 5.280880\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6625, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/64 (0%)]#011Loss: 5.258806\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6603, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/64 (0%)]#011Loss: 5.236471\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6580, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/64 (0%)]#011Loss: 5.195303\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6556, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/64 (0%)]#011Loss: 5.153681\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6530, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [0/64 (0%)]#011Loss: 5.141086\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6505, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [0/64 (0%)]#011Loss: 5.097819\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6473, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\n",
      "2024-11-24 20:22:31 Uploading - Uploading generated training model\u001b[34mTrain Epoch: 10 [0/64 (0%)]#011Loss: 5.069714\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.6439, Accuracy: 0/8 (0%)\u001b[0m\n",
      "\u001b[34mTorchScript model saved to /opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 72%|███████▏  | 32.1M/44.7M [00:00<00:00, 336MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 344MB/s]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.35s/it]#0152it [00:02,  1.17s/it]#0152it [00:02,  1.20s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.48s/it]#0152it [00:02,  1.21s/it]#0152it [00:02,  1.26s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.62s/it]#0152it [00:03,  1.48s/it]#0152it [00:03,  1.52s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.49s/it]#0152it [00:02,  1.19s/it]#0152it [00:02,  1.25s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.52s/it]#0152it [00:02,  1.21s/it]#0152it [00:02,  1.27s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.45s/it]#0152it [00:02,  1.18s/it]#0152it [00:02,  1.23s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.43s/it]#0152it [00:02,  1.19s/it]#0152it [00:02,  1.24s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.38s/it]#0152it [00:02,  1.16s/it]#0152it [00:02,  1.20s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.41s/it]#0152it [00:02,  1.17s/it]#0152it [00:02,  1.22s/it]\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0151it [00:01,  1.42s/it]#0152it [00:02,  1.18s/it]#0152it [00:02,  1.23s/it]\u001b[0m\n",
      "\u001b[34m2024-11-24 20:22:25,199 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-24 20:22:39 Completed - Training job completed\n",
      "Training seconds: 109\n",
      "Billable seconds: 109\n"
     ]
    }
   ],
   "source": [
    "estimator=Estimator(\n",
    "    image_uri='598308907998.dkr.ecr.us-east-1.amazonaws.com/udacity-sagemaker-hpo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "estimator.fit(inputs=model_inputs, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c7e61f-8be3-4f07-826e-06191f90414f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name: udacity-sagemaker-hpo-2024-11-24-20-20-00-150\n",
      "Model Artifact Location: s3://sagemaker-us-east-1-598308907998/udacity-sagemaker-hpo-2024-11-24-20-20-00-150/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Get the latest training job name\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training Job Name: {training_job_name}\")\n",
    "\n",
    "# Get the model artifact location from the training job details\n",
    "response = sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "model_artifact = response[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(f\"Model Artifact Location: {model_artifact}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc42542-52b6-499e-b15e-38580aefd4dd",
   "metadata": {},
   "source": [
    "# Testing Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fc2e3bb-0705-4987-9333-71453dcb2584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artifact,  # Use the artifact location from the training job\n",
    "    role=estimator.role,       # Use the role from your estimator\n",
    "    entry_point=\"image/inference.py\",\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py3\",\n",
    "    image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.8.1-cpu-py36-ubuntu18.04\",  # PyTorch-Inference image\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69623137-c2b8-411e-b973-317986a06591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-598308907998/udacity-sagemaker-hpo-2024-11-24-20-20-00-150/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-598308907998/pytorch-inference-2024-11-24-20-26-25-124/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-24-20-26-29-479\n"
     ]
    }
   ],
   "source": [
    "transformer = pytorch_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=\"s3://udacity-deeplearning-project/inference/\",  # S3 location for output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9375d00c-5d9e-4add-879a-f74929ec9a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: pytorch-inference-2024-11-24-20-26-32-239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34m2024-11-24 20:31:35,030 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:35,237 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.4.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 2\u001b[0m\n",
      "\u001b[34mMax heap size: 952 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 2\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:35,248 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:35,286 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,405 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,429 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,677 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,678 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:36,689 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,250 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,482 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,486 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.32533645629883|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,487 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.539794921875|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,487 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,488 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6570.9375|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,488 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:798.8828125|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,489 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:14.3|#Level:Host|#hostname:42a730c6c470,timestamp:1732480297\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,741 [INFO ] W-9000-model_1-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,742 [INFO ] W-9000-model_1-stdout MODEL_LOG - [PID]42\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,742 [INFO ] W-9000-model_1-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,744 [INFO ] W-9000-model_1-stdout MODEL_LOG - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,750 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,781 [INFO ] W-9000-model_1-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,814 [INFO ] W-9001-model_1-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1-stdout MODEL_LOG - [PID]43\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1-stdout MODEL_LOG - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,816 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:37,821 [INFO ] W-9001-model_1-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,347 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 490\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,348 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:1930|#Level:Host|#hostname:42a730c6c470,timestamp:1732480298\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,361 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:49|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,436 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 532\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,437 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:2022|#Level:Host|#hostname:42a730c6c470,timestamp:1732480298\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:38,437 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:121|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,254 [INFO ] pool-1-thread-3 ACCESS_LOG - /169.254.255.130:55842 \"GET /ping HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,255 [INFO ] pool-1-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:55856 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:181.33|#ModelName:model,Level:Model|#hostname:42a730c6c470,requestID:6f24d8c2-4e79-42ed-a5b7-8c7a7cf096ca,timestamp:1732480303\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 182\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:55870 \"POST /invocations HTTP/1.1\" 200 196\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[34m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,254 [INFO ] pool-1-thread-3 ACCESS_LOG - /169.254.255.130:55842 \"GET /ping HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,255 [INFO ] pool-1-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:55856 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,297 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:181.33|#ModelName:model,Level:Model|#hostname:42a730c6c470,requestID:6f24d8c2-4e79-42ed-a5b7-8c7a7cf096ca,timestamp:1732480303\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 182\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:55870 \"POST /invocations HTTP/1.1\" 200 196\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,608 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[35m2024-11-24 20:31:43,609 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:42a730c6c470,timestamp:null\u001b[0m\n",
      "\u001b[32m2024-11-24T20:31:43.312:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "Batch transform completed. Check the output in the specified S3 bucket.\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=\"s3://udacity-deeplearning-project/sample/data/batch/\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(\"Batch transform completed. Check the output in the specified S3 bucket.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ce707-3d47-4a44-aa0e-784abd182860",
   "metadata": {
    "tags": []
   },
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
